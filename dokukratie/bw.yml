name: bw
description: PARLIS Baden-Württemberg

publisher:
  type: parliament
  name: Landtag von Baden-Württemberg
  url: https://www.landtag-bw.de
  jurisdiction:
    id: bw
    name: Baden-Württemberg

scraper:
  name: portala
  url: https://parlis.landtag-bw.de/parlis/

document_types:
  minor_interpellation: Kleine Anfrage
  major_interpellation: Große Anfrage

pipeline:

  # emit scrape criteria
  init:
    method: dokukratie.scrapers.operations:init
    params:
      url: https://parlis.landtag-bw.de/parlis/
      dateformat: "%d.%m.%Y"
      legislative_terms: 17  # earliest: 9
      document_types:
        - minor_interpellation
        # - major_interpellation
    handle:
      pass: fetch

  # initialize session for cookie & referer
  fetch:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: search

  # post request to actual search
  search:
    method: dokukratie.scrapers.portala:search
    params:
      url: https://parlis.landtag-bw.de/parlis/browse.tt.json
      query_template: dokukratie/scrapers/portala.query.bw.json
    handle:
      pass: parse_json


  # filter json data
  parse_json:
    method: dokukratie.scrapers.operations:parse_jq
    params:
      pattern: '{item_count: .item_count, report_id: .report_id}'
    handle:
      pass: fetch_results

  # fetch response based on `report_id`
  fetch_results:
    method: dokukratie.scrapers.portala:fetch_results
    params:
      url: https://parlis.landtag-bw.de/parlis/report.tt.html
    handle:
      pass: parse_results

  parse_results:
    method: dokukratie.scrapers.operations:parse
    params:
      items: './/div[contains(@class, "efxRecordRepeater")]'
      include_paths:
        - './/a[@class="fundstellenLinks"]'
      meta:
        title: './/a[@class="efxZoomShort-Vorgang"]'
        originators_raw: './/dl/dt[contains(text(), "Initiative")]/following-sibling::dd[1]/text()'
        interpellation_raw: './/a[@class="fundstellenLinks"]'
        procedure_id: './/dl/dt[contains(text(), "Vorgangs-ID")]/following-sibling::dd[1]/text()'
      skip_incremental:
        key:
          data: procedure_id
        target:
          stage: store
    handle:
      fetch: download  # yield pdf urls and detail metadata

  download:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: clean

  parse:
    method: dokukratie.scrapers.bw:parse
    params:
      skip_incremental:
        target:
          stage: store
    handle:
      fetch: fetch
      clean: clean

  clean:
    method: dokukratie.scrapers.operations:clean
    params:
      extract:
        interpellation_raw:
          - .*(Schriftliche|Kleine)\s+Anfrage(.*)?\s+(?P<interpellation_date>\d{2}\.\d{2}\.\d{4})\s+Drucksache\s+(?P<interpellation_reference>\d{1,2}\/\d+).*
          - .*(Schriftliche|Kleine)\s+Anfrage(.*)?\s+(?P<published_at>\d{2}\.\d{2}\.\d{4})\s+und\s+Antwort\s+(?P<answerers>.*)\s+Drucksache\s+(?P<reference>\d{1,2}\/\d+).*
          - .*(Schriftliche|Kleine)\s+Anfrage(.*)?\s+(?P<published_at>\d{2}\.\d{2}\.\d{4})\s+und\s+Antwort\s+Drucksache\s+(?P<reference>\d{1,2}\/\d+).*
      parse:
        originators:
          source: originators_raw
          split: ","
          patterns: (?P<name>.*)\((?P<party>.*)\)
      dateparser:
        dayfirst: true
    handle:
      pass: store

  # store document & metadata to disk
  store:
    method: dokukratie.scrapers.operations:store
