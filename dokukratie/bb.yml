name: bb
description: Parlamentsdokumentation Brandenburg

publisher:
  type: parliament
  name: Landtag Brandenburg
  url: https://www.landtag.brandenburg.de
  jurisdiction:
    id: bb
    name: Brandenburg

scraper:
  name: starweb
  version: 6.0.0
  url: https://www.parlamentsdokumentation.brandenburg.de

document_types:
  generic: ANTWORT

pipeline:

  # emit scrape criteria
  init:
    method: dokukratie.scrapers.starweb:init
    params:
      legislative_terms: 7
      document_types: generic
      url: https://www.parlamentsdokumentation.brandenburg.de/starweb/LBB/ELVIS/servlet.starweb?path=LBB/ELVIS/LISSH.web&AdvancedSearch=yes
      dateformat: "%d.%m.%Y"
    handle:
      pass: fetch

  # initialize session
  fetch:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: redirect

  # weird initial redirect via post form
  redirect:
    method: dokukratie.scrapers.starweb:post
    params:
      formdata:
        __action: 41
    handle:
      pass: search

  # perform search via post form
  search:
    method: dokukratie.scrapers.starweb:search
    params:
      fields:
        legislative_term: LISSH_WP_ADV
        document_type: LISSH_DTYP
        start_date: LISSH_DatumV
        end_date: LISSH_DatumB
      formdata:
        __action: 85
        LISSH_DART_ADV: DRUCKSACHE
        LimitMaximumHitCount: "S99{ITEMS -1:-100000}"
    handle:
      pass: parse_results

  parse_results:
    method: dokukratie.scrapers.starweb:parse_results
    params:
      item: './/div[@name="RecordRepeater"]'
      download_url: './div[@name="Repeat_DBE"]/div[@class="asideD noprint"]//a[@title="Gesamtdokument"]/@href'
      next_page:
        xpath: './/div[@id="seitenzahl"]//span[@name="NextRecsConditional"]'
        formdata:
          __action: 197
      meta:
        # reference, originators, etc..: store the full paragraph for each field,
        # extract the granular information later in `clean` stage
        title: './div[@name="Repeat_TYP"]/div[@class="topic"]/h4'
        keywords: './div[@name="Repeat_TYP"]/div[@class="topic"]/a'
        reference: './div[@name="Repeat_DBE"]/div[@class="topic2"]'
        originators: './div[@name="Repeat_TYP"]/div[@class="topic2"]/span[2]'
        answerers: './div[@name="Repeat_DBE"]/div[@class="topic2"]'
        published_at: './div[@name="Repeat_DBE"]/div[@class="topic2"]'
    handle:
      next_page: search  # resend search post form with next page
      pass: download  # yield pdf urls and detail metadata

  download:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: clean

  # extract & cleanup metadata
  clean:
    method: dokukratie.scrapers.operations:clean
    params:
      extractors:
        published_at: \d{2}\.\d{2}\.\d{4}
        originators: ([\w\s(),\.]+)(?=\s\d)
        answerers: Antwort\s\((\w+)\)
      parser:
        originators:
          split: ","
          pattern: (?P<name>.*)\((?P<party>.*)\)
      dateparser:
        dayfirst: true
    handle:
      pass: store

  store:
    method: dokukratie.scrapers.operations:store
