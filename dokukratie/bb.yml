name: bb
description: ELVIS Parlamentsdokumentation Brandenburg

publisher:
  type: parliament
  name: Landtag Brandenburg
  url: https://www.landtag.brandenburg.de
  jurisdiction:
    id: bb
    name: Brandenburg

scraper:
  name: starweb
  version: 6.0.0
  url: https://www.parlamentsdokumentation.brandenburg.de

document_types:
  interpellation: ANTWORT

pipeline:

  # emit scrape criteria
  init:
    method: dokukratie.scrapers.starweb:init
    params:
      legislative_terms:
        - 7
        # - 6
        # - 5
        # - 4
        # - 3
        # - 2
        # - 1
      document_types: interpellation
      url: https://www.parlamentsdokumentation.brandenburg.de/starweb/LBB/ELVIS/servlet.starweb?path=LBB/ELVIS/LISSH.web&AdvancedSearch=yes
      dateformat: "%d.%m.%Y"
    handle:
      pass: fetch

  # initialize session
  fetch:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: redirect

  # weird initial redirect via post form
  redirect:
    method: dokukratie.scrapers.starweb:post
    params:
      formdata:
        __action: 41
    handle:
      pass: search

  # perform search via post form
  search:
    method: dokukratie.scrapers.starweb:search
    params:
      fields:
        legislative_term: LISSH_WP_ADV
        document_type: LISSH_DTYP
        start_date: LISSH_DatumV
        end_date: LISSH_DatumB
      formdata:
        __action: 87
        LISSH_DART_ADV: DRUCKSACHE
        NumPerSegment: 1000000
        LimitMaximumHitCount: "S99{ITEMS -1:-100000}"
    handle:
      pass: parse_results

  parse_results:
    method: dokukratie.scrapers.starweb:parse_results
    params:
      item: './/div[@name="RecordRepeater"]'
      download_url: './div[@name="Repeat_DBE"]/div[@class="asideD noprint"]//a[@title="Gesamtdokument"]/@href'
      next_page:
        xpath: './/div[@id="seitenzahl"]//span[@name="NextRecsConditional"]'
        formdata:
          __action: 201
      meta:
        # reference, originators, etc..: store the full paragraph for each field,
        # extract the granular information later in `clean` stage
        title: './div[@name="Repeat_TYP"]/div[@class="topic"]/h4'
        keywords: './div[@name="Repeat_TYP"]/div[@class="topic"]/a'
        interpellation_raw: './div[@name="Repeat_TYP"]/div[@class="topic2"]/span[2]'
        answer_raw: './div[@name="Repeat_DBE"]/div[@class="topic2"]'
    handle:
      next_page: search  # resend search post form with next page
      pass: download  # yield pdf urls and detail metadata

  download:
    method: dokukratie.scrapers.operations:fetch
    handle:
      pass: clean

  # extract & cleanup metadata
  clean:
    method: dokukratie.scrapers.operations:clean
    params:
      extract:
        interpellation_raw: (?P<originators_raw>.*)\s+(?P<interpellation_date>\d{2}\.\d{2}\.\d{4})\s?Drucksache\s?(?P<interpellation_reference>\d{1,2}\/\d+)
        answer_raw: Antwort\s\((?P<answerers>.*)\)\s(?P<published_at>\d{2}\.\d{2}\.\d{4})\s(?P<reference>.*)
      parse:
        originators:
          source: originators_raw
          split: ","
          patterns:
            - (?P<name>.*)\s+\((?P<party>.*)\)
            - \((?P<party>.*)\)
            - (?P<party>.*)\)
            - \((?P<party>.*)
            - (?P<party>.*)
      dateparser:
        dayfirst: true
    handle:
      pass: store

  store:
    method: dokukratie.scrapers.operations:store
